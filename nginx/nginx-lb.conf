events {
    worker_connections 1024;
    use epoll;
}

http {
    # âœ… ADDED: Allow file uploads up to 600MB
    client_max_body_size 600M;

    # Upstream backend pool with load balancing
    upstream backend_pool {
        # Use least_conn for better distribution
        least_conn;
        
        # Health check
        keepalive 32;
        
        # Backend instances
        server backend-1:5000 weight=1 max_fails=3 fail_timeout=30s;
        server backend-2:5000 weight=1 max_fails=3 fail_timeout=30s;
        server backend-3:5000 weight=1 max_fails=3 fail_timeout=30s;
        
        # Backup servers (if needed)
        # server backend-4:5000 backup;
    }

    # Rate limiting zones
    # Note: nginx only supports r/s (per second) or r/m (per minute)
    # 10 requests/hour = ~0.003 requests/second, so we use 1r/m (1 request per minute) as minimum
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;
    limit_req_zone $binary_remote_addr zone=deploy_limit:10m rate=1r/m;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript 
               application/javascript application/json application/xml+rss;

    # Frontend
    server {
        listen 80;
        server_name _;

        # Frontend static files
        location / {
            proxy_pass http://frontend:80;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # API endpoints with rate limiting and load balancing
        location /api/ {
            limit_req zone=api_limit burst=20 nodelay;
            
            proxy_pass http://backend_pool;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Connection pooling
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            # Timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # Retry on failure
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
            proxy_next_upstream_tries 3;
        }

        # Deployment endpoints (no rate limit, but load balanced)
        location /deploy/ {
            proxy_pass http://backend_pool;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Long timeout for deployments
            proxy_connect_timeout 300s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
        }

        # Deploy stream (SSE) with rate limiting
        location /api/deploy-stream {
            limit_req zone=deploy_limit burst=1 nodelay;
            
            proxy_pass http://backend_pool;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # SSE configuration
            proxy_buffering off;
            proxy_cache off;
            proxy_set_header Connection '';
            proxy_http_version 1.1;
            chunked_transfer_encoding off;
            
            # Long timeout for streaming
            proxy_connect_timeout 600s;
            proxy_send_timeout 600s;
            proxy_read_timeout 600s;
        }

        # Health check (no rate limit, fast response)
        location /api/health {
            proxy_pass http://backend_pool;
            access_log off;
            proxy_connect_timeout 5s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
        }
    }
}